{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPython Notebooks y Programación Científica con NumPy\n",
    "### by Martín Villanueva, martin.villanueva@alumnos.usm.cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to IPython Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In-browser editing for code, with automatic syntax highlighting, indentation, and tab completion/introspection.\n",
    "* The ability to execute code from the browser, with the results of computations attached to the code which generated them. **It follows the cells paradigm, equals as Mathematica does.**\n",
    "* Displaying the result of computation using rich media representations, such as HTML, LaTeX, PNG, SVG, etc. For example, publication-quality figures rendered by the **matplotlib** library, can be included inline.\n",
    "* The ability to easily include mathematical notation within markdown cells using LaTeX, and rendered natively by MathJax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaTeX integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaTeX has native suport in notebooks through *mathjax* extension. So you can write math LaTeX code inside a *'markdown cell'* as usual:\n",
    "$$\n",
    "\\min_{u} \\mathcal{J}(u) = \\min_{u} \\int_{\\Omega} (u-f)^2 + \\alpha \\cdot \\Phi_1(|\\nabla u|^2) \\ d\\Omega\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f80d264a5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Magic to plot matplotlib graphs in output cell (inside notebook)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "t = np.arange(0., 15., 0.2)\n",
    "f = np.cos(t)\n",
    "plt.plot(t, f, 'b--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful magic built-in functions for profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# install it with your favorite package manager, or with pip (if packages are not in a repository) \n",
    "# 'pip install line-profiler' and 'pip install memory_profiler'\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **time**: See how long it takes a code to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 829 µs, sys: 0 ns, total: 829 µs\n",
      "Wall time: 831 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time {1+2 for i in range(10000)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **timeit**: See how long a code takes to run averaged over multiple runs.  It will limit the number of runs depending on how long the script takes to execute.  Provide an accurate time calculation by reducing the impact of startup or shutdown costs on the time calculation by executing the code repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 590 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit {1+2 for i in range(10000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 577 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 100 {1+2 for i in range(10000)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **prun**: See how long it took each function in a script to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def foo(): sleep(1)\n",
    "    \n",
    "def bar(): sleep(2)\n",
    "    \n",
    "def baz(): foo(),bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun baz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **lprun**: See how long it took each line in a function to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_func(n):\n",
    "    a = np.random.random(n)\n",
    "    b = np.random.random(n)\n",
    "    c = np.dot(a,b)\n",
    "    c.sum()\n",
    "    return c\n",
    "\n",
    "import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%lprun -f test_func test_func(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **memit**: See how much memory a code uses overall. %memit works a lot like %timeit except that the number of iterations is set with -r instead of -n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 61.45 MiB, increment: 0.35 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit -r 5 test.func1(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Python is so slow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** Python is Dynamically Typed rather than Statically Typed.** What this means is that at the time the program executes, the interpreter doesn't know the type of the variables that are defined. <img src='cint_vs_pyint.png' style=\"width: 300px;\">\n",
    "* **Python is interpreted rather than compiled.** A smart compiler can look ahead and optimize for repeated or unneeded operations, which can result in speed-ups. \n",
    "* **Python's object model can lead to inefficient memory access.** A NumPy array in its simplest form is a Python object build around a C array. That is, it has a pointer to a contiguous data buffer of values. A Python list, on the other hand, has a pointer to a contiguous buffer of pointers, each of which points to a Python object which in turn has references to its data (in this case, integers). <img src='array_vs_list.png' style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Numpy is so fast?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Computations follow the **Single Instruction Multiple Data** (SIMD) paradigm. So that NumPy can take advantage of vectorized instructions on modern CPUs, like Intel's SSE and AVX, AMD's XOP.\n",
    "<img src='devectorized.png' style=\"width: 350px;\", caption='asdf'>\n",
    "<img src='vectorized.png' style=\"width: 350px;\">\n",
    "* A NumPy array is described by metadata (number of dimensions, shape, data type, strides, and so on) and the data (which is stored in a **homogeneous and contiguous** blocks of memory).\n",
    "* **Array computations** can be written very efficiently in a low-level language like C (and a large part of NumPy is actually written in C). Aditionally many internal methods and functions are linked to highly optimized linear algebra libraries like **BLAS** (Basic Linear Algebra Subprograms) and **LAPACK** (Linear Algebra PACKage).\n",
    "* **Spatial locality** in memory access patterns results in significant performance gains, notably thanks to the CPU cache.  Indeed, the cache loads bytes in chunks from RAM to the CPU registers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see the problem..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of calculating the squared norm of a vector with the following 4 implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Python Lists implementation\n",
    "def norm_square_list(vector):\n",
    "    norm = 0\n",
    "    for v in vector:\n",
    "        norm += v*v\n",
    "    return norm\n",
    "\n",
    "#Naive NumPy implementation\n",
    "def norm_square_array(vector):\n",
    "    norm = 0\n",
    "    for v in vector:\n",
    "        norm += v*v\n",
    "    return norm\n",
    "\n",
    "#Vectorized NumPy implementation\n",
    "def norm_square_numpy(vector):\n",
    "    return np.sum(vector * vector)\n",
    "\n",
    "#Clever NumPy implementation\n",
    "def norm_square_dot(vector):\n",
    "    return np.dot(vector, vector)\n",
    "\n",
    "#Vector to use - dimension 10^6\n",
    "vector = range(1000000)\n",
    "npvector = np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 91 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#Timing the list implementation\n",
    "%timeit norm_square_list(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.02 s per loop\n"
     ]
    }
   ],
   "source": [
    "#Timing the naive array implementation\n",
    "%timeit norm_square_array(npvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.47 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#Timing the NumPy-vectorized implementation\n",
    "%timeit norm_square_numpy(npvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.46 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#Timing the clever NumPy-vectorized implementation\n",
    "%timeit norm_square_dot(npvector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some interesting things have happened:\n",
    "* The naive array implementation, which iterates over data is actually slower than simply using a list. This is because the *array* stores a  very low-level representation of the numbers it stores , and this **must be converted** into Python-compatible version before being returned to user, causing this extra overhead each time you index an *array*.\n",
    "* *norm_square_numpy* is slower than the clever NumPy implementation because two reasons: 1) There is time spend in allocating memory for storing the temporary result *(vector x vector)* and 2) This creates two **implied loops**, one to do the multiplication and one to do the sum.\n",
    "* The clever implementation uses *np.dot()* NumPy function which has no need to store intermediate results, and iterates just one time (but at C speed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eficient programming with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-place and implicit copy operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefer in-place over implicit-copy operations whenever possible. This will save memory (less work to garbage collector) and performs faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def id(x):\n",
    "    # This function returns the memory\n",
    "    # block address of an array.\n",
    "    return x.__array_interface__['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array computations can involve **in-place** operations (first example below: the array is modified) or **implicit-copy** operations (second example: a new array is created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.zeros(10); aid = id(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-place operation\n",
    "a *= 2; id(a) == aid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implicit-copy operation\n",
    "a = a * 2; id(a) == aid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to choose the type of operation you actually need. Implicit-copy operations are **slower!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 751 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "a = np.ones(100000000)\n",
    "a *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 962 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = np.ones(100000000)\n",
    "b = a * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient memory access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **array slicing**, **masks** and **fancy indexing** (in this order) to eliminate loops. If you find yourself looping over indices to select items on which operation is performed, it can probably be done more efficiently with one of these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m, n = 1000000, 100\n",
    "a = np.random.random_sample((m, n))\n",
    "index = np.arange(0, m, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 228 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#fancy indexing - indexing with lists\n",
    "%timeit a[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 loops, best of 3: 1.45 µs per loop\n"
     ]
    }
   ],
   "source": [
    "#memory slice - memory views\n",
    "%timeit a[::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Array slices are implemented as memory views, i.e, refer to the original data buffer of an array, but with different offsets, shapes and strides.\n",
    "* Array views should be used whenever possible, but one needs to be careful about the fact that views refer to the original data buffer.\n",
    "* Fancy indexing is several orders of magnitude slower as it involves copying a large array.\n",
    "\n",
    "Another useful indexing technique is mask of booleans. Lets suppose we want to get all the elements on array with value less than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, ..., False, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def naive_indexing(vect):\n",
    "    ret = list()\n",
    "    for val in vect:\n",
    "        if val < 0.5: ret.append(val)\n",
    "    return np.array(ret)\n",
    "\n",
    "#data to occupy and mask of booleans\n",
    "vect = np.random.random_sample(1000000)\n",
    "mask = vect < 0.5\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 369 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#naive indexing\n",
    "%timeit naive_indexing(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 9.35 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#mask indexing\n",
    "%timeit vect[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 11.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "#'improved' mask indexing\n",
    "%timeit np.compress(mask, vect, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A powerful feature of Numpy is the concept of *ufunc* short for \"universal function.\" These functions operate on every value of an array **without need of loops**. This must be used instead for iterating over the array (eliminate loops!) and computing over each single data element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  9, 16, 25, 36, 49, 64, 81])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arithmetic operations like +,-,*,/ are implemented as binary ufuncs\n",
    "x = np.arange(10)\n",
    "x*x #multiply each element of x by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.84147098,  0.90929743,  0.14112001, -0.7568025 ,\n",
       "       -0.95892427, -0.2794155 ,  0.6569866 ,  0.98935825,  0.41211849])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy provides a lot of standar unary ufuncs\n",
    "# np.sin, np.cos, np.tan, np.exp, np.log, np.sinh, np.cosh and so on.\n",
    "np.sin(x) #take the sine of each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to always reshape arrays before operate on them. This useful feature implemented in NumPy arrays is called **Broadcasting rules.** In the visualization below, the extra memory indicated by the dotted boxes is never allocated, but it can be convenient to think about the operations as if it is.\n",
    "<img src='broadcasting.png' style=\"width: 400px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array([0,1,2]) + 5\n",
    "np.arange(3) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 1.,  2.,  3.],\n",
       "       [ 1.,  2.,  3.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array([[1, 1 ,1], [1, 1, 1], [1, 1, 1]]) + array([0, 1, 2])\n",
    "np.ones((3,3)) + np.arange(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array([[0], [1], [2]]) + array([0, 1 ,2])\n",
    "np.arange(3).reshape((3,1)) + np.arange(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Algorithms with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorization:** *The process of converting a scalar implementation, which processes a single pair of operands at a time, to a vector implementation, which processes one operation on multiple pairs of operands at once.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Gram-Shmidt Orthogonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The problem**: Given a matrix $Q_{m\\times n}$ with ($m>n$), find a vector $v$ orthogonal to the column space of $Q$. \n",
    "<img src='orthogonalization.jpg' style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naive_orth(Q,v):\n",
    "    m,n = Q.shape\n",
    "    for j in range(n):\n",
    "        v -= np.dot(Q[:,j],v)*Q[:,j]\n",
    "    return v\n",
    "    \n",
    "def vectorized_orth(Q,v):\n",
    "    proy = np.dot(Q.transpose(),v)\n",
    "    # v -= (proy*Q).sum(axis=1)\n",
    "    v -= np.dot(Q,proy)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's generate a random unitary matrix\n",
    "# Q unitary matrix, dimensions 100000 x1000\n",
    "m,n = 10000,100\n",
    "A = 10 * np.random.random((m,n))\n",
    "Q,R = np.linalg.qr(A, mode='reduced')\n",
    "del R\n",
    "\n",
    "# v will be the starting vector for orthogonalization\n",
    "v = np.random.random(m)\n",
    "v1 = v.copy()\n",
    "v2 = v.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 8.82 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit naive_orth(Q,v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.73 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit vectorized_orth(Q,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Limits of Vectorized Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets suppose we want to evaluate the complicated function $f(x,y) = e^{(x-y)^2 + (x+y)^2}\\cdot(\\cos{(x\\ y)} + \\sin{(x\\ y)}- \\cos{(x)}\\sin{(y)})$ on a set of data points $\\mathbf{x}=[x_0,\\ldots,x_n]$ and $\\mathbf{y}=[y_0,\\ldots,y_n]$ in a vectorized way. The question is, ** what is the problem with vectorized algorithms?**\n",
    "* It takes time to **allocate memory** for the temporary arrays (and many unnecessary temporaries are created).\n",
    "* It takes time to reclaim the memory of these arrays during **garbage collection**.\n",
    "* It takes time to **traverse the memory** – generally, computation on large arrays is often memory-bound – the run-time performance largely depends on how many times you have to scan the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vec_func(x,y):\n",
    "    return np.exp(np.sqrt((x-y)**2 + (x+y)**2))*(np.cos(x*y) + np.sin(x*y) - np.cos(x)*np.cos(y))\n",
    "\n",
    "#devec is a dynamic module, written in Cython\n",
    "import devec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A devectorized version of vec_func() was implemented with Cython as follows\n",
    "<img src='devec_code.png' style=\"width: 700px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random data to be used\n",
    "x0 = 10 * np.random.random(10000000)\n",
    "y0 = 10 * np.random.random(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 4.33 s per loop\n"
     ]
    }
   ],
   "source": [
    "#time of vectorized function\n",
    "%timeit vec_func(x0,y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1417.88 MiB, increment: 362.96 MiB\n"
     ]
    }
   ],
   "source": [
    "#memory of vectorized function\n",
    "%memit vec_func(x0,y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 3.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "#time of devectorized function\n",
    "%timeit devec.func(x0,y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1130.54 MiB, increment: 75.52 MiB\n"
     ]
    }
   ],
   "source": [
    "#memory of devectorized function\n",
    "%memit devec.func(x0,y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Warning :** By default, timeit() temporarily turns off garbage collection during the timing. The advantage of this approach is that it makes independent timings more comparable. This disadvantage is that GC may be an important component of the performance of the function being measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Useful libraries based in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy.linalg (Numpy's submodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.random.random((100,100))\n",
    "b = np.random.random(100)\n",
    "c = np.random.random(100)\n",
    "\n",
    "### Matrix power ###\n",
    "np.linalg.matrix_power(A,3)\n",
    "\n",
    "### Cholesky decomposition ###\n",
    "#np.linalg.cholesky(A) #A must be positive definite\n",
    "\n",
    "### QR decomposition ###\n",
    "np.linalg.qr(A, mode='reduced')\n",
    "\n",
    "### SVD decomposition ###\n",
    "np.linalg.svd(A, full_matrices=False)\n",
    "\n",
    "### Eigenvectors ###\n",
    "np.linalg.eig(A)\n",
    "\n",
    "### Eigevalues ###\n",
    "np.linalg.eigvals(A)\n",
    "\n",
    "### Matrix or vector norm ###\n",
    "np.linalg.norm(A, ord='fro')\n",
    "\n",
    "### Condition number ###\n",
    "np.linalg.cond(A, p=np.inf)\n",
    "\n",
    "### Determinant ###\n",
    "np.linalg.det(A)\n",
    "\n",
    "### Linear solver Ax=b ###\n",
    "np.linalg.solve(A,b)\n",
    "\n",
    "### Least Squares Ax=b (over-determined) ###\n",
    "np.linalg.lstsq(A,b)\n",
    "\n",
    "### Inverse ###\n",
    "np.linalg.inv(A)\n",
    "\n",
    "### Pseudo-Inverse ###\n",
    "np.linalg.pinv(A)\n",
    "\n",
    "### and many more...\n",
    "del A,b,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scipy.optimize(SciPy's submodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* bisect(f, a, b[, args, xtol, rtol, maxiter, ...]) -  \tFind root of a function within an interval.\n",
    "* newton(func, x0[, fprime, args, tol, ...]) -\tFind a zero using the Newton-Raphson or secant method.\n",
    "* fixed_point(func, x0[, args, xtol, maxiter]) -\tFind a fixed point of the function.\n",
    "* root(fun, x0[, args, method, jac, tol, ...]) -\tFind a root of a vector function.\n",
    "* fsolve(func, x0[, args, fprime, ...]) -\tFind the roots of a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scipy.integrate (Scipy's submodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cumtrapz(y[, x, dx, axis, initial]) -\tCumulatively integrate y(x) using the composite trapezoidal rule.\n",
    "* simps(y[, x, dx, axis, even]) -\tIntegrate y(x) using samples along the given axis and the composite Simpson’s rule.\n",
    "* fixed_quad(func, a, b[, args, n]) -\tCompute a definite integral using fixed-order Gaussian quadrature.\n",
    "* quadrature(func, a, b[, args, tol, rtol, ...]) -\tCompute a definite integral using fixed-tolerance Gaussian quadrature.\n",
    "* odeint(func, y0, t[, args, Dfun, col_deriv, ...]) -\tIntegrate a system of ordinary differential equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [*IPython notebook oficial documentation*](http://ipython.readthedocs.org/en/stable/)\n",
    "* [*Time and memory Profiling in IPython*](http://pynash.org/2013/03/06/timing-and-profiling.html)\n",
    "* [*Getting the best performance out of NumPy*](http://ipython-books.github.io/featured-01/)\n",
    "* [*Why Python is slow*](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/)\n",
    "* [*High Performance Python: Practical Performant Programming for Humans*](https://books.google.cl/books?id=bIZaBAAAQBAJ&pg=PA115&lpg=PA115&dq#v=onepage&q&f=false)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
